{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb7caf1-d497-47d4-bb56-29cebbbf0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from keras import Model\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, Dense, Dropout, LSTM, Flatten\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, Dense, Dropout, LSTM, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, average_precision_score\n",
    "import seaborn as sb\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1378674-c024-4ed7-a268-3b72b5bc8e40",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136eab4-c1d8-4e34-8f74-c45dcd79cc9c",
   "metadata": {},
   "source": [
    "# Project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab60abd-5f52-439d-adc6-7f7904f2a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = \"clickbait v2_Copy2\"\n",
    "p_dir = os.path.join(\"../cb models\", m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e613fb55-5d2f-4243-9629-ee6c1b7746b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path: str):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e638914-f00f-47c1-8a79-d0b7634b932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir(dir_path: str):\n",
    "    for item in os.listdir(dir_path):\n",
    "        fp = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(fp):\n",
    "            os.remove(fp)\n",
    "        if os.path.isdir(fp):\n",
    "            rmtree(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa790f0-108f-417c-bcb1-a202b4276df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(p_dir)\n",
    "clear_dir(p_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd81eaf-3fc1-4164-85cb-1aa4437b4b0a",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a343e58-9680-43ef-962f-2745591b961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31865, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../cb models/clickbait_data.csv\")\n",
    "df.rename(columns={\"headline\": \"title\"}, inplace=True)\n",
    "df = df.loc[df.title.str.len() <= 100, :]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f94f1b-1a70-40bc-a8ca-4ccb4b17e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31865 entries, 0 to 31999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   title      31865 non-null  object\n",
      " 1   clickbait  31865 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 746.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1cba22-14ae-4b19-a9a3-69cbff60e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cat_lbl = [\"very low\", \"low\", \"high\", \"very high\"]\n",
    "# df.loc[:, \"clickbait\"] = pd.qcut(df.clickbait, len(cat_lbl), labels=cat_lbl, precision=6)\n",
    "df[\"clickbait\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8d10ac-b4c6-4065-a610-305c87aac877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25492 6373\n"
     ]
    }
   ],
   "source": [
    "y = df[\"clickbait\"]\n",
    "x = df.loc[:, [c for c in df if c != \"clickbait\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=4711)\n",
    "\n",
    "x_train.to_pickle(os.path.join(p_dir, \"x_train.pkl\"))\n",
    "y_train.to_pickle(os.path.join(p_dir, \"y_train.pkl\"))\n",
    "# x_val.to_pickle(os.path.join(p_dir,\"x_val.pkl\"))\n",
    "# y_val.to_pickle(os.path.join(p_dir, \"y_val.pkl\"))\n",
    "x_test.to_pickle(os.path.join(p_dir,\"x_test.pkl\"))\n",
    "y_test.to_pickle(os.path.join(p_dir, \"y_test.pkl\"))\n",
    "\n",
    "print(x_train.shape[0], x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dd4f5-2316-4c13-814f-bb82fbbfbcfd",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b48ead1-df29-45bf-993b-2af2f9332542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df: pd.DataFrame, remove_stopwords: bool=False) -> pd.DataFrame:\n",
    "    field = \"title\"\n",
    "    stw = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def cleanse_row(row, field, stw, stopwords=False):\n",
    "        # Remove HTML from text\n",
    "        soup = BeautifulSoup(row[field])\n",
    "        row[field] = soup.get_text()\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if stopwords:\n",
    "            row[field] = \" \".join([w for w in row[field].split() if w not in stw])\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    df = df.apply(lambda row: cleanse_row(row, field, stw, remove_stopwords), axis=1)\n",
    "    return df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617db1f3-c98b-4d8f-b91e-2256e00f8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwork corpus\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc38b67-9a38-4a22-b06a-8b257022f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = False\n",
    "\n",
    "def preprocess_data(x: pd.DataFrame, remove_stopwords: bool=False) -> list():\n",
    "    x_pp = preprocessing(x, remove_stopwords)\n",
    "    x_pp = x_pp.tolist()\n",
    "    return x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff8d289-87c9-47d9-877a-07ce7dc5701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pp = preprocess_data(x_train)\n",
    "x_test_pp = preprocess_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a51e5e-b095-4c07-b6cb-7f71c8bfabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = \"roberta-base\"\n",
    "tok = RobertaTokenizer.from_pretrained(pt_model, do_lower=True, add_special_tokens=True, max_length=100, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836216a9-c9ad-4652-b778-d46c9fe414e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=100, padding=\"max_length\", return_attention_mask=True,\n",
    "                                       return_token_type_ids=True, truncation=True)\n",
    "        input_ids.append(inputs[\"input_ids\"])\n",
    "        input_masks.append(inputs[\"attention_mask\"])\n",
    "        input_segments.append(inputs[\"token_type_ids\"])\n",
    "        \n",
    "    return np.asarray(input_ids, dtype=\"int32\"), np.asarray(input_masks, dtype=\"int32\"), np.asarray(input_segments, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ffeac75-92b3-4928-9a57-2c8ad23bc83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:17:19.570634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:19.578934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:19.579558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:19.580731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-18 11:17:19.581711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:19.582368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:19.582927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:20.079839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:20.080601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:20.081292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 11:17:20.081882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "transformer_model = TFRobertaModel.from_pretrained(pt_model)\n",
    "\n",
    "in_ids = Input(shape=(100,), name=\"input_token\", dtype=\"int32\")\n",
    "in_masks = Input(shape=(100,), name=\"masked_token\", dtype=\"int32\")\n",
    "\n",
    "emb = transformer_model(in_ids, attention_mask=in_masks)[0]\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0))(emb)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=[in_ids, in_masks], outputs=x)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17369283-81ef-48b8-8361-a76eee288830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=Adam(learning_rate=0.0005), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2493475-7197-4b61-8855-014d1cd5f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 100, 100)     327600      tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           5050        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            102         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 124,978,384\n",
      "Trainable params: 332,752\n",
      "Non-trainable params: 124,645,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f529aa-5e27-4f1d-9e14-4b46c6706627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:17:33.391152: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:17:45.474730: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 227s 539ms/step - loss: 0.0629 - accuracy: 0.9796 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01869, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 2/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0175 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01869 to 0.01747, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 3/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0131 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01747 to 0.01313, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 4/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0203 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01313\n",
      "Epoch 5/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0115 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01313 to 0.01148, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 6/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0083 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01148 to 0.00829, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 7/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0096 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00829\n",
      "Epoch 8/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0082 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00829 to 0.00816, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 9/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00816\n",
      "Epoch 10/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00816\n",
      "Epoch 11/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0084 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00816\n",
      "Epoch 12/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00816\n",
      "Epoch 13/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00816 to 0.00680, saving model to ../cb models/clickbait v2_Copy2/clickbait v2_Copy2\n",
      "Epoch 14/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0113 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00680\n",
      "Epoch 15/20\n",
      "399/399 [==============================] - 212s 531ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00680\n",
      "Epoch 16/20\n",
      "399/399 [==============================] - 212s 532ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0074 - val_accuracy: 0.9970\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00680\n",
      "Epoch 17/20\n",
      "164/399 [===========>..................] - ETA: 1:42 - loss: 0.0034 - accuracy: 0.9985"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15515/2237185208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  callbacks=[checkpoint, es])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_tok = tokenize(x_train_pp, tok)\n",
    "x_test_tok = tokenize(x_test_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "y_test_b = lb.transform(y_test)\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "\n",
    "metric = \"val_loss\"\n",
    "\n",
    "es = EarlyStopping(monitor=metric, \n",
    "                   mode=\"min\", \n",
    "                   patience=5, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(p_dir, \"{}\".format(m_name)), \n",
    "                             monitor=metric, \n",
    "                             verbose=2, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "hist = model.fit(x_train_tok[:2], y_train_b, \n",
    "                 validation_data=(x_test_tok[:2], y_test_b), \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=n_epochs, \n",
    "                 callbacks=[checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bf6d7-4f18-48e4-acad-6fdb12a2f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(hist.history[\"accuracy\"])\n",
    "axs[0].plot(hist.history[\"val_accuracy\"])\n",
    "axs[0].set_title(\"model accuracy\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].set_xlabel(\"epoch\")\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "axs[1].plot(hist.history[\"loss\"])\n",
    "axs[1].plot(hist.history[\"val_loss\"])\n",
    "axs[1].set_title(\"model loss\")\n",
    "axs[1].set_ylabel(\"loss\")\n",
    "axs[1].set_xlabel(\"epoch\")\n",
    "axs[1].set_ylim(0, 1)\n",
    "axs[1].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"accuracy_loss.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be28e06-01dc-4231-aa62-586940507864",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbda95-2962-477a-9a75-9b2f1ec19a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(p_dir, \"{}\".format(m_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288de96-0c6a-407d-9acd-0662a8c19a7a",
   "metadata": {},
   "source": [
    "## Training data (in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe8174-f5be-41a3-82b8-0e3182e01679",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tok = tokenize(x_train_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "\n",
    "y_train_prob = model.predict(x_train_tok[:2], steps=y_train_b.shape[0])\n",
    "y_pred = np.argmax(y_train_prob, axis=1)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa1fac-291d-4ff7-9d02-330bec3a15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_train, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=lb.classes_, yticklabels=lb.classes_)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - training set\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix_train.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_train, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0268a9-3bdb-4b65-8abb-d468f5708611",
   "metadata": {},
   "source": [
    "## Test data (out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c67f17-0fa4-4c3d-ae4a-4be4068488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pp = preprocess_data(x_test)\n",
    "x_test_tok = tokenize(x_test_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "y_test_b = lb.transform(y_test)\n",
    "\n",
    "y_test_prob = model.predict(x_test_tok[:2], steps=y_test_b.shape[0])\n",
    "y_pred = np.argmax(y_test_prob, axis=1)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a21694-da4a-4797-bbac-986044f3647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score: {:0.2f}\".format(f1_score(y_test_b, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefaeb3-6182-49fb-abe0-9506744485fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=lb.classes_, yticklabels=lb.classes_)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - test set\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix_test.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "\n",
    "# print(classification_report(y_test, y_pred, target_names=lb.classe_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5638e19-d2ee-46b2-92c8-494c342d0d7a",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eda2d-52f2-49d9-b929-4942e123a209",
   "metadata": {},
   "source": [
    "## Training data (in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68f8eb-5c1c-42cb-b513-8f787a6058b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit_transform(y_train)\n",
    "\n",
    "y_train_no = lb.fit_transform(y_train)\n",
    "y_pred_no = y_train_prob[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_train_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f78bf-02e6-4d81-a6dc-b5fc34d9294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_train_no, y_pred_no)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - training dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve_train.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1731a9-a449-4152-bca6-db35ea1a6037",
   "metadata": {},
   "source": [
    "## Test data (out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491579a-ea65-4d16-a42e-ea6daea8b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit_transform(y_train)\n",
    "\n",
    "y_test_no = lb.fit_transform(y_test)\n",
    "y_pred_no = y_test_prob[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_test_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1b5b1-5cac-4a07-9630-ef4ec4f44324",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_test_no, y_pred_no)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - test dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve_test.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f8a50-6086-4732-b5a2-a3df8e9a91af",
   "metadata": {},
   "source": [
    "# Class probability histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751e8ab-d41e-4c34-9d75-da652a526025",
   "metadata": {},
   "source": [
    "## Without middle classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd16914-63f8-4da9-98dc-db37d20b1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = y_test_no[:, 0] == 0\n",
    "c0 = y_test_prob[m0, 1]\n",
    "m1 = y_test_no[:, 0] == 1\n",
    "c1 = y_test_prob[m1, 1]\n",
    "\n",
    "plt.hist(c0, alpha=0.3, bins=20)\n",
    "plt.hist(c1, color=\"red\", alpha=0.3, bins=20)\n",
    "plt.title(\"Histogram\")\n",
    "plt.legend(lb.classes_)\n",
    "plt.savefig(os.path.join(p_dir, \"histogram.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d8bab-407e-4813-8f77-a81176523657",
   "metadata": {},
   "source": [
    "# Sample titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f33c91-dfd9-49f4-b8e6-81339df93eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([x_test, y_test], axis=1)\n",
    "combo.reset_index(drop=True, inplace=True)\n",
    "combo = pd.concat([combo, pd.Series(y_pred, name=\"pred\")], axis=1)\n",
    "combo.rename(columns={\"clickbait\": \"truth\"}, inplace=True)\n",
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317ca4e-f0de-4648-9bfe-1528f4c57122",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = combo.groupby([\"pred\"], as_index=False).apply(lambda x: x.sample(5, random_state=682))\n",
    "g[[\"title\", \"pred\"]].head(10)\n",
    "g.to_csv(os.path.join(p_dir, \"titles.csv\"), index=False)\n",
    "g.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec673a-2137-416c-a64c-ad041832b868",
   "metadata": {},
   "source": [
    "# Save test set pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ddfd1-01f7-41f9-b26f-9c44a56b1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.Series(y_pred, name=\"y_pred_test\")\n",
    "y_pred_test.to_pickle(os.path.join(p_dir, \"y_pred_test.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
