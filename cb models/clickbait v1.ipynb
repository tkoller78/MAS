{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb7caf1-d497-47d4-bb56-29cebbbf0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from keras import Model\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, Dense, Dropout, LSTM, Flatten\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, Dense, Dropout, LSTM, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, average_precision_score, f1_score\n",
    "import seaborn as sb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9325fb-da7e-4795-9585-757064928b4c",
   "metadata": {},
   "source": [
    "Data source: https://zenodo.org/record/5530410#.YYfo3GDML-g (2017 Clickbait challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136eab4-c1d8-4e34-8f74-c45dcd79cc9c",
   "metadata": {},
   "source": [
    "# Project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab60abd-5f52-439d-adc6-7f7904f2a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = \"clickbait v1\"\n",
    "p_dir = os.path.join(\"../cb models\", m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e613fb55-5d2f-4243-9629-ee6c1b7746b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path: str):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e638914-f00f-47c1-8a79-d0b7634b932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir(dir_path: str):\n",
    "    for item in os.listdir(dir_path):\n",
    "        fp = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(fp):\n",
    "            os.remove(fp)\n",
    "        if os.path.isdir(fp):\n",
    "            rmtree(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa790f0-108f-417c-bcb1-a202b4276df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(p_dir)\n",
    "clear_dir(p_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd81eaf-3fc1-4164-85cb-1aa4437b4b0a",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a343e58-9680-43ef-962f-2745591b961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19538, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../cb models/clickbait.pkl\")\n",
    "df = df.loc[df.title.str.len() <= 100, :]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f94f1b-1a70-40bc-a8ca-4ccb4b17e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19538 entries, 0 to 19537\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   title      19538 non-null  object\n",
      " 1   clickbait  19538 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 457.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1cba22-14ae-4b19-a9a3-69cbff60e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"clickbait\"] = (df[\"clickbait\"] == \"clickbait\").astype(\"int32\")\n",
    "df[\"clickbait\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb694b4b-78a2-4299-9861-cb594b8074d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "undersampler = RandomOverSampler()\n",
    "x = df.title\n",
    "y = df.clickbait\n",
    "x, y = undersampler.fit_resample(x.to_frame(), y)\n",
    "\n",
    "y.hist()\n",
    "plt.show()\n",
    "# The data is about equally distributed between clickbaity and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8d10ac-b4c6-4065-a610-305c87aac877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23643 5911\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=4711)\n",
    "\n",
    "x_train.to_pickle(os.path.join(p_dir, \"x_train.pkl\"))\n",
    "y_train.to_pickle(os.path.join(p_dir, \"y_train.pkl\"))\n",
    "# x_val.to_pickle(os.path.join(p_dir,\"x_val.pkl\"))\n",
    "# y_val.to_pickle(os.path.join(p_dir, \"y_val.pkl\"))\n",
    "x_test.to_pickle(os.path.join(p_dir,\"x_test.pkl\"))\n",
    "y_test.to_pickle(os.path.join(p_dir, \"y_test.pkl\"))\n",
    "\n",
    "print(x_train.shape[0], x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dd4f5-2316-4c13-814f-bb82fbbfbcfd",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b48ead1-df29-45bf-993b-2af2f9332542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df: pd.DataFrame, remove_stopwords: bool=False) -> pd.DataFrame:\n",
    "    field = \"title\"\n",
    "    stw = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def cleanse_row(row, field, stw, stopwords=False):\n",
    "        # Remove HTML from text\n",
    "        soup = BeautifulSoup(row[field])\n",
    "        row[field] = soup.get_text()\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if stopwords:\n",
    "            row[field] = \" \".join([w for w in row[field].split() if w not in stw])\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    df = df.apply(lambda row: cleanse_row(row, field, stw, remove_stopwords), axis=1)\n",
    "    return df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617db1f3-c98b-4d8f-b91e-2256e00f8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwork corpus\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc38b67-9a38-4a22-b06a-8b257022f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = False\n",
    "\n",
    "def preprocess_data(x: pd.DataFrame, remove_stopwords: bool=False) -> list():\n",
    "    x_pp = preprocessing(x, remove_stopwords)\n",
    "    x_pp = x_pp.tolist()\n",
    "    return x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff8d289-87c9-47d9-877a-07ce7dc5701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pp = preprocess_data(x_train)\n",
    "x_test_pp = preprocess_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a51e5e-b095-4c07-b6cb-7f71c8bfabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = \"roberta-base\"\n",
    "tok = RobertaTokenizer.from_pretrained(pt_model, do_lower=True, add_special_tokens=True, max_length=100, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836216a9-c9ad-4652-b778-d46c9fe414e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=100, padding=\"max_length\", return_attention_mask=True, \n",
    "                                       return_token_type_ids=True, truncation=True)\n",
    "        input_ids.append(inputs[\"input_ids\"])\n",
    "        input_masks.append(inputs[\"attention_mask\"])\n",
    "        input_segments.append(inputs[\"token_type_ids\"])\n",
    "        \n",
    "    return np.asarray(input_ids, dtype=\"int32\"), np.asarray(input_masks, dtype=\"int32\"), np.asarray(input_segments, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ffeac75-92b3-4928-9a57-2c8ad23bc83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 16:53:10.968388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:10.976509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:10.977116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:10.978767: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-17 16:53:10.979614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:10.980291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:10.980863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:11.457487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:11.458175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:11.458748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-17 16:53:11.459293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig(dropout=0.2, attention_dropout=0.2)\n",
    "config.output_hidden_states=False\n",
    "transformer_model = TFRobertaModel.from_pretrained(pt_model)\n",
    "\n",
    "in_ids = Input(shape=(100,), name=\"input_token\", dtype=\"int32\")\n",
    "in_masks = Input(shape=(100,), name=\"masked_token\", dtype=\"int32\")\n",
    "\n",
    "emb = transformer_model(in_ids, attention_mask=in_masks)[0]\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0))(emb)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=[in_ids, in_masks], outputs=x)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17369283-81ef-48b8-8361-a76eee288830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=Adam(learning_rate=0.0005), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2493475-7197-4b61-8855-014d1cd5f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 100, 100)     327600      tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           5050        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            102         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 124,978,384\n",
      "Trainable params: 332,752\n",
      "Non-trainable params: 124,645,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f529aa-5e27-4f1d-9e14-4b46c6706627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 16:53:20.464626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 16:53:32.385051: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 200s 510ms/step - loss: 0.6953 - accuracy: 0.5007 - val_loss: 0.6930 - val_accuracy: 0.5047\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69297, saving model to ../cb models/clickbait v1/clickbait v1\n",
      "Epoch 2/20\n",
      "190/370 [==============>...............] - ETA: 1:16 - loss: 0.6935 - accuracy: 0.5007"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4381/2237185208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  callbacks=[checkpoint, es])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_tok = tokenize(x_train_pp, tok)\n",
    "x_test_tok = tokenize(x_test_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "y_test_b = lb.transform(y_test)\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "\n",
    "metric = \"val_loss\"\n",
    "\n",
    "es = EarlyStopping(monitor=metric, \n",
    "                   mode=\"min\", \n",
    "                   patience=5, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(p_dir, \"{}\".format(m_name)), \n",
    "                             monitor=metric, \n",
    "                             verbose=2, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "hist = model.fit(x_train_tok[:2], y_train_b, \n",
    "                 validation_data=(x_test_tok[:2], y_test_b), \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=n_epochs, \n",
    "                 callbacks=[checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bf6d7-4f18-48e4-acad-6fdb12a2f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(hist.history[\"accuracy\"])\n",
    "axs[0].plot(hist.history[\"val_accuracy\"])\n",
    "axs[0].set_title(\"model accuracy\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].set_xlabel(\"epoch\")\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "axs[1].plot(hist.history[\"loss\"])\n",
    "axs[1].plot(hist.history[\"val_loss\"])\n",
    "axs[1].set_title(\"model loss\")\n",
    "axs[1].set_ylabel(\"loss\")\n",
    "axs[1].set_xlabel(\"epoch\")\n",
    "axs[1].set_ylim(0, 1)\n",
    "axs[1].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"accuracy_loss.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be28e06-01dc-4231-aa62-586940507864",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbda95-2962-477a-9a75-9b2f1ec19a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(p_dir, \"{}\".format(m_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288de96-0c6a-407d-9acd-0662a8c19a7a",
   "metadata": {},
   "source": [
    "## Training data (in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe8174-f5be-41a3-82b8-0e3182e01679",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tok = tokenize(x_train_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "\n",
    "y_train_prob = model.predict(x_train_tok[:2], steps=y_train_b.shape[0])\n",
    "y_pred = np.argmax(y_train_prob, axis=1)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa1fac-291d-4ff7-9d02-330bec3a15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_train, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=lb.classes_, yticklabels=lb.classes_)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - training set\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix_train.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_train, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_train, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_train, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_train, y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0268a9-3bdb-4b65-8abb-d468f5708611",
   "metadata": {},
   "source": [
    "## Test data (out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c67f17-0fa4-4c3d-ae4a-4be4068488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pp = preprocess_data(x_test)\n",
    "x_test_tok = tokenize(x_test_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "y_test_b = lb.transform(y_test)\n",
    "\n",
    "y_test_prob = model.predict(x_test_tok[:2], steps=y_test_b.shape[0])\n",
    "y_pred = np.argmax(y_test_prob, axis=1)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc40fa0-88fb-495f-9253-476562290ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score: {:0.2f}\".format(f1_score(y_test, y_pred, pos_label=\"very high\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefaeb3-6182-49fb-abe0-9506744485fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=lb.classes_, yticklabels=lb.classes_)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - test set\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix_test.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "\n",
    "# print(classification_report(y_test, y_pred, target_names=lb.classe_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5638e19-d2ee-46b2-92c8-494c342d0d7a",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eda2d-52f2-49d9-b929-4942e123a209",
   "metadata": {},
   "source": [
    "## Training data (in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68f8eb-5c1c-42cb-b513-8f787a6058b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit_transform(y_train)\n",
    "\n",
    "y_train_no = lb.fit_transform(y_train)\n",
    "y_pred_no = y_train_prob[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_train_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f78bf-02e6-4d81-a6dc-b5fc34d9294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_train_no, y_pred_no)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - training dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve_train.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1731a9-a449-4152-bca6-db35ea1a6037",
   "metadata": {},
   "source": [
    "## Test data (out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491579a-ea65-4d16-a42e-ea6daea8b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit_transform(y_train)\n",
    "\n",
    "y_test_no = lb.fit_transform(y_test)\n",
    "y_pred_no = y_test_prob[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_test_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1b5b1-5cac-4a07-9630-ef4ec4f44324",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_test_no, y_pred_no)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - test dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve_test.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f8a50-6086-4732-b5a2-a3df8e9a91af",
   "metadata": {},
   "source": [
    "# Class probability histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751e8ab-d41e-4c34-9d75-da652a526025",
   "metadata": {},
   "source": [
    "## Without middle classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd16914-63f8-4da9-98dc-db37d20b1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = y_test_no[:, 0] == 0\n",
    "c0 = y_test_prob[m0, 1]\n",
    "m1 = y_test_no[:, 0] == 1\n",
    "c1 = y_test_prob[m1, 1]\n",
    "\n",
    "plt.hist(c0, alpha=0.3, bins=20)\n",
    "plt.hist(c1, color=\"red\", alpha=0.3, bins=20)\n",
    "plt.title(\"Histogram\")\n",
    "plt.legend(lb.classes_)\n",
    "plt.savefig(os.path.join(p_dir, \"histogram.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d8bab-407e-4813-8f77-a81176523657",
   "metadata": {},
   "source": [
    "# Sample titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f33c91-dfd9-49f4-b8e6-81339df93eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([x_test, y_test], axis=1)\n",
    "combo.reset_index(drop=True, inplace=True)\n",
    "combo = pd.concat([combo, pd.Series(y_pred, name=\"pred\")], axis=1)\n",
    "combo.rename(columns={\"clickbait\": \"truth\"}, inplace=True)\n",
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317ca4e-f0de-4648-9bfe-1528f4c57122",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = combo.groupby([\"pred\"], as_index=False).apply(lambda x: x.sample(5, random_state=682))\n",
    "g[[\"title\", \"pred\"]].head(10)\n",
    "g.to_csv(os.path.join(p_dir, \"titles.csv\"), index=False)\n",
    "g.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec673a-2137-416c-a64c-ad041832b868",
   "metadata": {},
   "source": [
    "# Save test set pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ddfd1-01f7-41f9-b26f-9c44a56b1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.Series(y_pred, name=\"y_pred_test\")\n",
    "y_pred_test.to_pickle(os.path.join(p_dir, \"y_pred_test.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51893100-e8b2-4051-95ca-6ec474446390",
   "metadata": {},
   "source": [
    "# Apply model on Youtube data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c15ea-73e1-4854-8101-db283693deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d747091-7060-4e38-a52c-2654859c17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dir = r\"../nlp models/roberta_2_classes\"\n",
    "\n",
    "x_alien = pd.read_pickle(os.path.join(m_dir, \"x_train.pkl\"))\n",
    "y_alien = pd.read_pickle(os.path.join(m_dir, \"y_train.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9046140-089f-4ff7-bbf8-d72e5fc6be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_alien_pp = preprocess_data(x_alien)\n",
    "x_alien_tok = tokenize(x_alien_pp, tok)\n",
    "\n",
    "y_alien_prob = model.predict(x_alien_tok[:2], steps=y_alien.shape[0])\n",
    "y_pred = np.argmax(y_alien_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0a301-c489-4abf-9bb4-bdf51436f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combo = pd.concat([x_alien.reset_index(), y_alien.reset_index(), pd.Series(y_pred, name=\"pred\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd72840-c4f4-42d7-b988-d37e2219664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combo[[\"title\", \"qtl\", \"pred\"]].iloc[412:418, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e4563-e3d1-4e7b-b0e4-17f6e7c82186",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combo[\"y\"] = (x_combo[\"qtl\"] == \"very high\").astype(\"int32\")\n",
    "x_combo[\"y\"].corr(x_combo[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b670bb-1892-4ef4-933d-1410d3259b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = x_combo.groupby([\"qtl\", \"pred\"]).agg({\"title\": \"count\"}).reset_index()\n",
    "g.rename(columns={\"pred\": \"clickbait\", \"title\": \"count\"}, inplace=True)\n",
    "p = g.pivot(index=\"qtl\", columns=\"clickbait\", values=\"count\")\n",
    "sb.heatmap(p, annot=True, fmt=\"d\")\n",
    "plt.title(\"Clickbait model vs. ground truth\")\n",
    "plt.xlabel(\"clickbait\")\n",
    "plt.ylabel(\"prediction main model\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion matrix clickbait vs ground truth.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d82a08-640e-441c-8b46-c6d902f14c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combo.loc[(x_combo[\"qtl\"] == \"very high\") & (x_combo[\"pred\"] == 0), \"title\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcfce64-7cec-4f0d-b071-9ade7a666c82",
   "metadata": {},
   "source": [
    "Why is the correlation not higher?\n",
    "\n",
    "* Video thumbnails and titles can be changed over the lifetime of a Youtube video\n",
    "* This might be related to the sample being from science/educational video. The typical viewer seems to also be attracted by videos clearly stating their content (Derek Muller also mentions such as case -> lava lamp video). May be because he is looking for something specific or because she is interested in the topic anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef6cad-65ae-493c-a528-d01230b1028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8548842-baf8-47c0-a8de-c2859fd2ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = x_combo.groupby([\"channel_name\"]).agg({\"id_video\": \"count\", \"pred\": \"sum\", \"y\": \"sum\"}).reset_index()\n",
    "g.rename(columns={\"id_video\": \"video_count\", \"pred\": \"clickbait\", \"y\": \"very high\"}, inplace=True)\n",
    "g[\"vh_ratio\"] = g[\"very high\"] / g[\"video_count\"]\n",
    "g[\"cb_ratio\"] = g[\"clickbait\"] / g[\"video_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eaf7b-e15f-4c01-a380-a2109ade8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = [\"very low\", \"low\", \"high\", \"very high\"]\n",
    "g[\"success class\"] = pd.cut(g[\"vh_ratio\"], 4, labels=lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f29dfd-a867-4d8b-ba69-9bc0cca31ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\"red\", \"orange\", \"green\", \"blue\"]\n",
    "i = 0\n",
    "for l in lbl:\n",
    "    plt.scatter(g.loc[g[\"success class\"] == l, \"cb_ratio\"], g.loc[g[\"success class\"] == l, \"vh_ratio\"], c=c[i])\n",
    "    i += 1\n",
    "plt.xlabel(\"clickbait ratio\")\n",
    "plt.ylabel(\"\\'very high\\' video ratio\")\n",
    "plt.title(\"Video success per channel\")\n",
    "plt.savefig(os.path.join(p_dir, \"channel level corr clickbait vs video success.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da49519-f289-42f3-84ac-1e25ec415e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = g[\"cb_ratio\"].corr(g[\"vh_ratio\"])\n",
    "print(\"{:0.2f}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ec05a-bfd3-4cf1-a261-02299fdfa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = g.loc[(g[\"cb_ratio\"] < 0.3) & (g[\"vh_ratio\"] > 0.8), :]\n",
    "sp.sort_values([\"vh_ratio\", \"cb_ratio\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8aa56-dc48-4cfe-8314-ee2aaa4d2258",
   "metadata": {},
   "source": [
    "Removing the 2 channels with a clickbait ratio of 0 but at the same time being super successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e366b03-f340-43b5-9ed4-1312c7f30181",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.loc[(g[\"cb_ratio\"] == 0), \"channel_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4ec2e-d3ef-486a-8708-638573604548",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = g.loc[(g[\"cb_ratio\"] > 0), \"cb_ratio\"].corr(g.loc[(g[\"cb_ratio\"] > 0), \"vh_ratio\"])\n",
    "print(\"{:0.2f}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8619971-c196-44f3-a17b-266de5f2d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = g.loc[~((g[\"cb_ratio\"] < 0.3) & (g[\"vh_ratio\"] > 0.8)), \"cb_ratio\"].corr(\n",
    "    g.loc[~((g[\"cb_ratio\"] < 0.3) & (g[\"vh_ratio\"] > 0.8)), \"vh_ratio\"])\n",
    "print(\"{:0.2f}\".format(c2))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
