{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bfd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, Reshape, AveragePooling2D\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, LSTM\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from keras import Input\n",
    "from keras.initializers import he_normal\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from shutil import rmtree, copyfile\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, average_precision_score\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "import re\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdffdbf",
   "metadata": {},
   "source": [
    "# Project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66b699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = \"combo model img_test\"\n",
    "p_dir = os.path.join(\"../combo models\", m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32dc8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path: str):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c4cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir(dir_path: str):\n",
    "    for item in os.listdir(dir_path):\n",
    "        fp = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(fp):\n",
    "            os.remove(fp)\n",
    "        if os.path.isdir(fp):\n",
    "            rmtree(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b206d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(p_dir)\n",
    "clear_dir(p_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c25593",
   "metadata": {},
   "source": [
    "# Read and transform scraped dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a296d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../scraped data\"\n",
    "\n",
    "channels = pd.read_pickle(os.path.join(fp, \"channels.pkl\"))\n",
    "videos = pd.read_pickle(os.path.join(fp, \"videos.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15921549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_channels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Date string into proper date\n",
    "    df.published = pd.to_datetime(df.published)\n",
    "    \n",
    "    # Convert field type into int64\n",
    "    fields = [\"video_count\", \"view_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"int64\")\n",
    "    \n",
    "    # Convert field type into float64\n",
    "    fields = [\"subscriber_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"float64\")\n",
    "    \n",
    "    # Add of channel in months\n",
    "    df[\"age_mth\"] = (pd.to_datetime(\"today\", utc=True).year - df.published.dt.year) * 12 \\\n",
    "        + (pd.to_datetime(\"today\", utc=True).month - df.published.dt.month)\n",
    "        \n",
    "    # Drop unnecessary fields\n",
    "    df.drop(columns=[\"custom_url\", \"country\"] + [c for c in df.columns if c.startswith(\"thumbnail\")], inplace=True)\n",
    "    \n",
    "    # Remove channels without subscriber_count\n",
    "    df = df.loc[df.subscriber_count.notnull(), :]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8953baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_videos(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    # Date string into proper date\n",
    "    df.published = pd.to_datetime(df.published)\n",
    "    \n",
    "    # Convert field type to bool\n",
    "    fields = [\"broadcast\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"bool\")\n",
    "    \n",
    "    # Convert field type into int64\n",
    "    fields = [\"category_id\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"int64\")\n",
    "    \n",
    "    # Convert field type into float64\n",
    "    fields = [\"comment_count\", \"dislike_count\", \"like_count\", \"view_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"float64\")\n",
    "    \n",
    "    df[\"published_mth\"] = (pd.to_datetime(\"today\", utc=True).year - df.published.dt.year) * 12 \\\n",
    "        + (pd.to_datetime(\"today\", utc=True).month - df.published.dt.month)\n",
    "    df[\"title_len\"] = df.title.str.len()\n",
    "    \n",
    "    df.drop(columns=[\"favorite_count\", \"broadcast\", \"audio_language\", \"comment_count\", \"category_id\"] \\\n",
    "            + [c for c in df.columns if c.startswith(\"thumbnail\")], inplace=True)\n",
    "    \n",
    "    df = df.loc[df.like_count.notnull() & df.dislike_count.notnull() & df.view_count.notnull(), :]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19374c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_trans = transform_channels(channels)\n",
    "videos_trans = transform_videos(videos)\n",
    "combo = videos_trans.merge(channels_trans[[\"id\", \"view_count\",\"published\", \"age_mth\", \"subscriber_count\",\n",
    "                                             \"video_count\"]], \n",
    "                           how=\"inner\", left_on=\"channel_id\", right_on=\"id\", suffixes=[\"_video\", \"_channel\"])\n",
    "combo[\"ln_vc_norm\"] = np.log(combo.view_count_video / combo.subscriber_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d800c",
   "metadata": {},
   "source": [
    "# Define categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9529bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_lbl = [\"very low\", \"low\", \"high\", \"very high\"]\n",
    "combo.loc[:, \"qtl\"] = pd.qcut(combo.ln_vc_norm, len(cat_lbl), labels=cat_lbl, precision=6)\n",
    "combo.sort_values(by=[\"qtl\"]).qtl.hist()\n",
    "plt.title(\"Counts of classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26808f50",
   "metadata": {},
   "source": [
    "# Split dataset (use only top and bottom quartile data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ecc83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5793 1931 1932\n"
     ]
    }
   ],
   "source": [
    "cat_lbl = [\"very low\", \"very high\"]\n",
    "combo = combo.loc[combo.qtl.isin(cat_lbl)]\n",
    "combo.qtl = combo.qtl.cat.remove_unused_categories()\n",
    "\n",
    "y = combo.qtl\n",
    "x = combo.loc[:, [c for c in combo.columns if c != \"qtl\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=4711)\n",
    "\n",
    "x_train.to_pickle(os.path.join(p_dir, \"x_train.pkl\"))\n",
    "y_train.to_pickle(os.path.join(p_dir, \"y_train.pkl\"))\n",
    "x_val.to_pickle(os.path.join(p_dir,\"x_val.pkl\"))\n",
    "y_val.to_pickle(os.path.join(p_dir, \"y_val.pkl\"))\n",
    "x_test.to_pickle(os.path.join(p_dir,\"x_test.pkl\"))\n",
    "y_test.to_pickle(os.path.join(p_dir, \"y_test.pkl\"))\n",
    "\n",
    "print(x_train.shape[0], x_val.shape[0], x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e829a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5516971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_model():\n",
    "    \n",
    "    inp = Input(shape=(90, 120, 3))\n",
    "    \n",
    "    base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_tensor=inp)\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = AveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(len(cat_lbl), activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(base_model.input, out)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(learning_rate=0.0005), \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6156b82-fe3b-4501-8f96-1aaa2a6b95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6b4084-7caf-4d15-b3b9-d972743ed0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nlp_model():\n",
    "    config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "    config.output_hidden_states=False\n",
    "    transformer_model = TFDistilBertModel.from_pretrained(pt_model, config=config)\n",
    "\n",
    "    in_ids = Input(shape=(100,), name=\"input_token\", dtype=\"int32\")\n",
    "    in_masks = Input(shape=(100,), name=\"masked_token\", dtype=\"int32\")\n",
    "\n",
    "    emb = transformer_model(in_ids, attention_mask=in_masks)[0]\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0))(emb)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[in_ids, in_masks], outputs=x)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de1b70eb-082b-4744-86fb-2b3c4af99273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Load image model with weights and remove last layer\n",
    "    m_name = \"densenet_2_classes_bce_fmt\"\n",
    "    img_model = create_img_model()\n",
    "    img_model.load_weights(\"../img models/{a}/{a}\".format(a=m_name))\n",
    "    for layer in img_model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return img_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e384558-78e1-412a-a537-0aac814ae55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 11:22:37.514695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:37.593321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:37.594242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:37.595704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-24 11:22:37.596842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:37.597614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:37.598347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:39.668902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:39.669624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:39.670255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 11:22:39.670804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effd4c73-bed6-4ded-8590-42ba00e0c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd75641-d27b-409c-ba7c-075acfa8e6c7",
   "metadata": {},
   "source": [
    "# Text preprocessing and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294830d4-097e-496c-aab1-f13180acb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_sentence(txt: str, remove_stopwords: bool=False) -> str:\n",
    "    field = \"title\"\n",
    "    stw = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def cleanse_row(txt, field, stw, stopwords=False):\n",
    "        # Remove HTML from text\n",
    "        soup = BeautifulSoup(txt)\n",
    "        txt = soup.get_text()\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if stopwords:\n",
    "            txt = \" \".join([w for w in txt.split() if w not in stw])\n",
    "        \n",
    "        return txt\n",
    "    \n",
    "    txt = cleanse_row(txt, field, stw, remove_stopwords)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6685c059-bffe-40f6-968d-5bd5d31e484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwork corpus\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d66e307-e3fa-4461-bc2d-ffed317aeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = False\n",
    "\n",
    "def preprocess_data(x: pd.DataFrame, remove_stopwords: bool=False) -> list():\n",
    "    x_pp = preprocessing(x, remove_stopwords)\n",
    "    x_pp = x_pp.tolist()\n",
    "    return x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1455a8e7-f61a-4921-9dc4-252ee9504165",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = DistilBertTokenizer.from_pretrained(pt_model, do_lower=True, add_special_tokens=True, max_length=100, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a91bb92-dc4a-4c7b-894a-a007cb9f6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=100, padding=\"max_length\", return_attention_mask=True, \n",
    "                                   return_token_type_ids=True)\n",
    "    input_ids.append(inputs[\"input_ids\"])\n",
    "    input_masks.append(inputs[\"attention_mask\"])\n",
    "    input_segments.append(inputs[\"token_type_ids\"])\n",
    "        \n",
    "    return np.asarray(input_ids, dtype=\"int32\"), np.asarray(input_masks, dtype=\"int32\"), np.asarray(input_segments, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e490ae",
   "metadata": {},
   "source": [
    "# Prepare DataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9736cf11-2035-4d4c-9606-02c946714d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TkDataGenerator(Sequence):\n",
    "    def __init__(self, df, img_col, txt_col, y_col, img_dir, img_pp_func, txt_pp_func, tok_func, tokenizer, lb, batch_size=32, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.shuffle = shuffle\n",
    "        self.img_pp_func = img_pp_func\n",
    "        self.txt_pp_func = txt_pp_func\n",
    "        self.tok_func = tok_func\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lb = lb\n",
    "        self.img_col = img_col\n",
    "        self.txt_col = txt_col\n",
    "        self.y_col = y_col\n",
    "        self.lb = lb\n",
    "        self.img_dir = img_dir\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        x1, x2, x3, y = self.__get_data(batch)\n",
    "        return x1, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        x1 = np.empty((self.batch_size, *(90, 120, 3)), dtype=\"float32\")\n",
    "        x2 = np.empty((self.batch_size, 100))\n",
    "        x3 = np.empty((self.batch_size, 100))        \n",
    "        y = np.empty((self.batch_size, 2), dtype=\"float32\")\n",
    "        \n",
    "        for i, i_df in enumerate(batch):\n",
    "            img = load_img(os.path.join(img_dir, \"{}.jpg\".format(self.df.loc[i_df, self.img_col])), target_size=(90, 120))\n",
    "            img = self.img_pp_func(np.array(img)).astype(\"float32\")\n",
    "            pp = self.txt_pp_func(self.df.loc[i_df, self.txt_col])\n",
    "            t1, t2, t3 = self.tok_func(pp, self.tokenizer)\n",
    "            \n",
    "            x1[i] = img\n",
    "            x2[i] = t1\n",
    "            x3[i] = t2\n",
    "            y[i] = np.array([int(l == self.df.loc[i_df, self.y_col]) for l in self.lb])\n",
    "            \n",
    "        return x1, x2, x3, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e00350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(X, y, img_dir, lb, batch_size):\n",
    "    combo = pd.concat([X, y], axis=\"columns\")\n",
    "    combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "    datagen = TkDataGenerator(df=combo, \n",
    "                              img_col=\"id_video\", \n",
    "                              txt_col=\"title\",\n",
    "                              y_col=\"qtl\",\n",
    "                              img_dir=img_dir, \n",
    "                              img_pp_func=preprocess_input, \n",
    "                              txt_pp_func=preprocessing_sentence, \n",
    "                              tok_func=tokenize,\n",
    "                              lb=lb,\n",
    "                              tokenizer=tok, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True)\n",
    "    return datagen\n",
    "\n",
    "def val_generator(X, y, img_dir, lb, batch_size):\n",
    "    combo = pd.concat([X, y], axis=\"columns\")\n",
    "    combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "    datagen = TkDataGenerator(df=combo, \n",
    "                              img_col=\"id_video\", \n",
    "                              txt_col=\"title\",\n",
    "                              y_col=\"qtl\",\n",
    "                              img_dir=img_dir, \n",
    "                              img_pp_func=preprocess_input, \n",
    "                              txt_pp_func=preprocessing_sentence, \n",
    "                              tok_func=tokenize,\n",
    "                              lb=lb,\n",
    "                              tokenizer=tok, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True)\n",
    "    return datagen\n",
    "\n",
    "def test_generator(X, y, img_dir, lb):\n",
    "    combo = pd.concat([X, y], axis=\"columns\")\n",
    "    combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "    datagen = TkDataGenerator(df=combo, \n",
    "                              img_col=\"id_video\", \n",
    "                              txt_col=\"title\",\n",
    "                              y_col=\"qtl\",\n",
    "                              img_dir=img_dir, \n",
    "                              img_pp_func=preprocess_input, \n",
    "                              txt_pp_func=preprocessing_sentence, \n",
    "                              tok_func=tokenize,\n",
    "                              lb=lb,\n",
    "                              tokenizer=tok, \n",
    "                              batch_size=1, \n",
    "                              shuffle=False)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb09a53b-ee1d-4851-9e3b-6f817b4d691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x_train.iloc[2:6,]\n",
    "yt = y_train.iloc[2:6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36931173-4919-4964-b33e-5a1da9129951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.0665298, -2.0357141, -1.8044444],\n",
       "        [-2.0665298, -2.0357141, -1.8044444],\n",
       "        [-2.0665298, -2.0357141, -1.8044444],\n",
       "        ...,\n",
       "        [-2.0494049, -2.0357141, -1.7347276],\n",
       "        [-2.0494049, -2.0357141, -1.7347276],\n",
       "        [-2.0494049, -2.0357141, -1.7347276]],\n",
       "\n",
       "       [[-2.117904 , -2.0182073, -1.8044444],\n",
       "        [-2.117904 , -2.0182073, -1.8044444],\n",
       "        [-2.117904 , -2.0182073, -1.8044444],\n",
       "        ...,\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444]],\n",
       "\n",
       "       [[-2.117904 , -2.0182073, -1.7347276],\n",
       "        [-2.117904 , -2.0182073, -1.7347276],\n",
       "        [-2.117904 , -2.0182073, -1.7347276],\n",
       "        ...,\n",
       "        [-2.117904 , -1.9831933, -1.8044444],\n",
       "        [-2.117904 , -1.9831933, -1.8044444],\n",
       "        [-2.117904 , -1.9831933, -1.8044444]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        ...,\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444]],\n",
       "\n",
       "       [[-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        ...,\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444]],\n",
       "\n",
       "       [[-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        ...,\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444],\n",
       "        [-2.117904 , -2.0357141, -1.8044444]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = \"../images\"\n",
    "batch_size = 3\n",
    "\n",
    "combo = pd.concat([xt, yt], axis=\"columns\")\n",
    "combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "\n",
    "tg = TkDataGenerator(df=combo, \n",
    "                      img_col=\"id_video\", \n",
    "                      txt_col=\"title\",\n",
    "                      y_col=\"qtl\",\n",
    "                      img_dir=img_dir, \n",
    "                      img_pp_func=preprocess_input, \n",
    "                      txt_pp_func=preprocessing_sentence, \n",
    "                      tok_func=tokenize,\n",
    "                      lb=cat_lbl,\n",
    "                      tokenizer=tok, \n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=False)\n",
    "\n",
    "# tg = train_generator(xt, yt, img_dir, cat_lbl, batch_size)\n",
    "tg[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac19815e-7717-4237-923c-0745e712697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_generator(X, y, img_dir, batch_size):\n",
    "#     combo = pd.concat([X, y], axis=\"columns\")\n",
    "#     combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "#     datagen = ImageDataGenerator(preprocessing_function=preprocess_input,)\n",
    "#     gen = datagen.flow_from_dataframe(dataframe=combo,\n",
    "#                                       directory=img_dir,\n",
    "#                                       x_col=\"file_name\", \n",
    "#                                       y_col=\"qtl\",\n",
    "#                                       class_mode=\"categorical\",\n",
    "#                                       color_mode=\"rgb\",\n",
    "#                                       target_size=(90, 120),\n",
    "#                                       shuffle=True,\n",
    "#                                       batch_size=batch_size                                      \n",
    "#                                      )\n",
    "#     return gen\n",
    "\n",
    "# def val_generator(X, y, img_dir, batch_size):\n",
    "#     combo = pd.concat([X, y], axis=\"columns\")\n",
    "#     combo[\"file_name\"] = combo.id_video + \".jpg\"\n",
    "#     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#     gen = datagen.flow_from_dataframe(dataframe=combo,\n",
    "#                                       directory=img_dir,\n",
    "#                                       x_col=\"file_name\", \n",
    "#                                       y_col=\"qtl\",\n",
    "#                                       class_mode=\"categorical\",\n",
    "#                                       color_mode=\"rgb\",\n",
    "#                                       target_size=(90, 120),\n",
    "#                                       shuffle=True,\n",
    "#                                       batch_size=batch_size                                      \n",
    "#                                      )\n",
    "#     return gen\n",
    "\n",
    "# ig = train_generator(xt, yt, img_dir, batch_size)\n",
    "# ig[0][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6430b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7c51d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 11:22:49.035358: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 11:22:55.836762: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 58s 444ms/step - loss: 0.7581 - accuracy: 0.6585 - val_loss: 0.4439 - val_accuracy: 0.7911\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44395, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 13s 142ms/step - loss: 0.4132 - accuracy: 0.8200 - val_loss: 0.4285 - val_accuracy: 0.7901\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44395 to 0.42850, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.3736 - accuracy: 0.8398 - val_loss: 0.4022 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42850 to 0.40218, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 12s 138ms/step - loss: 0.3410 - accuracy: 0.8576 - val_loss: 0.3950 - val_accuracy: 0.8234\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40218 to 0.39503, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 12s 135ms/step - loss: 0.3385 - accuracy: 0.8535 - val_loss: 0.3996 - val_accuracy: 0.8151\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39503\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 12s 135ms/step - loss: 0.3181 - accuracy: 0.8649 - val_loss: 0.3777 - val_accuracy: 0.8328\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39503 to 0.37771, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 12s 134ms/step - loss: 0.2986 - accuracy: 0.8753 - val_loss: 0.4224 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37771\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 12s 135ms/step - loss: 0.2827 - accuracy: 0.8847 - val_loss: 0.3706 - val_accuracy: 0.8375\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37771 to 0.37055, saving model to ../combo models/combo model img_test/combo model img_test\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 12s 135ms/step - loss: 0.2726 - accuracy: 0.8920 - val_loss: 0.3750 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37055\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 12s 139ms/step - loss: 0.2579 - accuracy: 0.8964 - val_loss: 0.4302 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37055\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 13s 140ms/step - loss: 0.2430 - accuracy: 0.9026 - val_loss: 0.4148 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37055\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 12s 135ms/step - loss: 0.2358 - accuracy: 0.9043 - val_loss: 0.4052 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37055\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 12s 138ms/step - loss: 0.2273 - accuracy: 0.9099 - val_loss: 0.4319 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.37055\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"../images\"\n",
    "batch_size = 64\n",
    "\n",
    "train_gen = train_generator(x_train, y_train, img_dir, cat_lbl, batch_size)\n",
    "val_gen = val_generator(x_val, y_val, img_dir, cat_lbl, batch_size)\n",
    "\n",
    "metric = \"val_loss\"\n",
    "\n",
    "es = EarlyStopping(monitor=metric, \n",
    "                   mode=\"min\", \n",
    "                   patience=5, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(p_dir, \"{}\".format(m_name)), \n",
    "                             monitor=metric, \n",
    "                             verbose=2, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "hist = model.fit(train_gen,\n",
    "                 epochs=200,\n",
    "                 validation_data=val_gen,\n",
    "                 verbose=1,\n",
    "                 callbacks=[checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5455af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(hist.history[\"accuracy\"])\n",
    "axs[0].plot(hist.history[\"val_accuracy\"])\n",
    "axs[0].set_title(\"model accuracy\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].set_xlabel(\"epoch\")\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "axs[1].plot(hist.history[\"loss\"])\n",
    "axs[1].plot(hist.history[\"val_loss\"])\n",
    "axs[1].set_title(\"model loss\")\n",
    "axs[1].set_ylabel(\"loss\")\n",
    "axs[1].set_xlabel(\"epoch\")\n",
    "# axs[1].set_ylim(0, 1)\n",
    "axs[1].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"accuracy_loss.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97534e98",
   "metadata": {},
   "source": [
    "# Sample images per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c14320ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1875/2903691672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qtl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"qtl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \"\"\"\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1875/2903691672.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id_video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qtl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"qtl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5363\u001b[0m             )\n\u001b[1;32m   5364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5365\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5366\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "s = combo.loc[combo[\"id_video\"].isin(x_train[\"id_video\"]), [\"id_video\", \"qtl\"]].groupby(\"qtl\", as_index=False).apply(lambda x: x.sample(5, random_state=15))\n",
    "\n",
    "n_images = 5\n",
    "fig, axs = plt.subplots(len(cat_lbl), n_images)\n",
    "i = 0\n",
    "\n",
    "for idx, row in s.iterrows():\n",
    "    img = Image.open(os.path.join(img_dir, \"{}.jpg\".format(row[\"id_video\"])))\n",
    "    axs[i // n_images, i % n_images].imshow(img)\n",
    "    axs[i // n_images, i % n_images].xaxis.set_ticklabels([])\n",
    "    axs[i // n_images, i % n_images].xaxis.set_ticks([])\n",
    "    axs[i // n_images, i % n_images].set_xlabel(row[\"qtl\"])\n",
    "    axs[i // n_images, i % n_images].yaxis.set_ticklabels([])\n",
    "    axs[i // n_images, i % n_images].yaxis.set_ticks([])\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample images - training data\")\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"sample_images.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecd621",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b08f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(p_dir, \"{}\".format(m_name)))\n",
    "model.load_weights(os.path.join(p_dir, \"{}\".format(m_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887bc28-f86d-4760-bfa4-f773f08138c7",
   "metadata": {},
   "source": [
    "## Validation dataset (in_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a82f3b-8d65-495a-bcab-506af3588452",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"../images\"\n",
    "\n",
    "x_val = pd.read_pickle(os.path.join(p_dir, \"x_val.pkl\"))\n",
    "y_val = pd.read_pickle(os.path.join(p_dir, \"y_val.pkl\"))\n",
    "val_gen = test_generator(x_val, y_val, img_dir, lb)\n",
    "y_val_prob = model.predict(val_gen, steps=y_val.shape[0])\n",
    "y_pred = np.argmax(y_val_prob, axis=1)\n",
    "y_pred = lb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330c228-ea8c-49a8-a757-5bdf0908496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_val, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=y_val.cat.categories, yticklabels=lb.classes_)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - validation set\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix_val.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_val, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_val, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_val, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_val, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_val, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_val, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_val, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_val, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_val, y_pred, average=\"weighted\")))\n",
    "\n",
    "print(classification_report(y_val, y_pred, target_names=cat_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a4591-f74b-4e48-a957-1de50f3672f3",
   "metadata": {},
   "source": [
    "## Test dataset (out-of_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"../images\"\n",
    "\n",
    "x_test = pd.read_pickle(os.path.join(p_dir, \"x_test.pkl\"))\n",
    "y_test = pd.read_pickle(os.path.join(p_dir, \"y_test.pkl\"))\n",
    "test_gen = test_generator(x_test, y_test, img_dir)\n",
    "y_pred_prob = model.predict(test_gen, steps=y_test.shape[0])\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "cls_lbl = dict([(v, k) for k, v in test_gen.class_indices.items()])\n",
    "y_pred = pd.Series([cls_lbl[i] for i in y_pred]).astype(\"category\").cat.reorder_categories(cat_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(cmtx, annot=True, fmt=\"d\", xticklabels=y_test.cat.categories, yticklabels=y_pred.cat.categories)\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.title(\"Confusion matrix - test set (out-of-sample)\")\n",
    "plt.savefig(os.path.join(p_dir, \"confusion_matrix.jpg\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:0.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(\"Micro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"micro\")))\n",
    "print(\"Micro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"Macro precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Macro F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "\n",
    "print(\"Weighted precision: {:0.2f}\".format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted recall: {:0.2f}\".format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print(\"Weighted F1-score: {:0.2f}\".format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=cat_lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c9068-68fd-4f27-87c2-c87d98ccc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = combo.loc[combo[\"id_video\"].isin(x_val[\"id_video\"]), [\"id_video\", \"qtl\"]].groupby(\"qtl\", as_index=False).apply(lambda x: x.sample(5, random_state=118))\n",
    "\n",
    "n_images = 5\n",
    "fig, axs = plt.subplots(len(cat_lbl), n_images)\n",
    "i = 0\n",
    "\n",
    "for idx, row in s.iterrows():\n",
    "    img = Image.open(os.path.join(img_dir, \"{}.jpg\".format(row[\"id_video\"])))\n",
    "    axs[i // n_images, i % n_images].imshow(img)\n",
    "    axs[i // n_images, i % n_images].xaxis.set_ticklabels([])\n",
    "    axs[i // n_images, i % n_images].xaxis.set_ticks([])\n",
    "    axs[i // n_images, i % n_images].set_xlabel(row[\"qtl\"])\n",
    "    axs[i // n_images, i % n_images].yaxis.set_ticklabels([])\n",
    "    axs[i // n_images, i % n_images].yaxis.set_ticks([])\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample images - test data\")\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"sample_images_val.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ffed6-dd9c-4415-94d3-5491b42dac4f",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27752c8a-b9f5-4d69-8d22-1cb5e40d7487",
   "metadata": {},
   "source": [
    "## Validation dataset (in sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda5977-ddcf-499e-853d-c3a7f794078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_val_no = lb.fit_transform(y_val)\n",
    "y_pred_no = y_val_prob[:, 1]\n",
    "fpr, tpr, thr = roc_curve(y_val_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b11426-e347-4c06-8071-52e20494cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_val_no, y_pred_no)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - validation dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve_val.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f88ad-5143-4045-b889-93e387325bdf",
   "metadata": {},
   "source": [
    "## Test dataset (out-of-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983768b9-1697-4ca4-8a77-2da60082b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_test_no = lb.fit_transform(y_test)\n",
    "y_pred_no = y_pred_prob[:,  1]\n",
    "fpr, tpr, thr = roc_curve(y_test_no, y_pred_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05c8ee-f16a-46ae-ad4e-844c21c1f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_model = auc(fpr, tpr)\n",
    "mavgp = average_precision_score(y_test_no, y_pred_no)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr, label=\"Model (auc={:0.4f}, mean avg. prec={:0.4f})\".format(auc_model, mavgp))\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curve - test set (out-of-sample)\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(p_dir, \"roc-curve.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc9a87-5b9b-484d-b4e7-e113e8f0034b",
   "metadata": {},
   "source": [
    "# Class probability histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6b939-43a9-4a4f-83dc-5b1e4da809e1",
   "metadata": {},
   "source": [
    "## Without middle classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4610d-e640-4971-998a-3c94ba6a648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = y_test_no[:, 0] == 0\n",
    "c0 = y_pred_prob[m0, 1]\n",
    "m1 = y_test_no[:, 0] == 1\n",
    "c1 = y_pred_prob[m1, 1]\n",
    "\n",
    "plt.hist(c0, alpha=0.3, bins=20)\n",
    "plt.hist(c1, color=\"red\", alpha=0.3, bins=20)\n",
    "plt.title(\"Histogram\")\n",
    "plt.legend(cat_lbl, loc=\"upper center\")\n",
    "plt.savefig(os.path.join(p_dir, \"histogram.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b7cc5-d4aa-45e6-9497-18397a15b380",
   "metadata": {},
   "source": [
    "## Including middle classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ab4f0-92ab-4e87-ae93-78e0fcfa0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_lbl2 = [\"very low\", \"low\", \"high\", \"very high\"]\n",
    "combo2 = combo.copy()\n",
    "combo2.loc[:, \"qtl\"] = pd.qcut(combo.ln_vc_norm, len(cat_lbl2), labels=cat_lbl2, precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3e2df-84b0-4d3d-8097-7965b348148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo2 = combo2.loc[combo2.qtl.isin([\"low\", \"high\"]), :]\n",
    "combo2.qtl = combo2.qtl.cat.remove_unused_categories()\n",
    "\n",
    "y2 = combo2.qtl\n",
    "x2 = combo2.loc[:, [c for c in combo2.columns if c != \"qtl\"]]\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "x_train2, x_val2, y_train2, y_val2 = train_test_split(x_train2, y_train2, test_size=0.25, random_state=4711)\n",
    "\n",
    "print(x_train2.shape[0], x_val2.shape[0], x_test2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff790bef-c8ea-4d73-85df-3c1701d1e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen2 = test_generator(x_test2, y_test2, img_dir)\n",
    "y_pred_prob2 = model.predict(test_gen2, steps=y_test2.shape[0])\n",
    "y_pred2 = np.argmax(y_pred_prob2, axis=1)\n",
    "cls_lbl = dict([(v, k) for k, v in test_gen.class_indices.items()])\n",
    "y_pred2 = pd.Series([cls_lbl[i] for i in y_pred2]).astype(\"category\").cat.reorder_categories(cat_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46607bae-e787-4846-aaa0-7e9e9702f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = y_test_no[:, 0] == 0\n",
    "c0 = y_pred_prob[m0, 1]\n",
    "m1 = y_test_no[:, 0] == 1\n",
    "c1 = y_pred_prob[m1, 1]\n",
    "\n",
    "m3 = y_test2 == \"low\"\n",
    "c2 = y_pred_prob2[m3, 0]\n",
    "\n",
    "m4 = y_test2 == \"high\"\n",
    "c3 = y_pred_prob2[m4, 0]\n",
    "\n",
    "plt.hist(c0, alpha=0.3, label=\"\", bins=20)\n",
    "plt.hist(c1, color=\"red\", alpha=0.3, label=\"\", bins=20)\n",
    "plt.hist(c2, color=\"green\", alpha=0.3, label=\"\", bins=20)\n",
    "plt.hist(c3, color=\"yellow\", alpha=0.3, label=\"\", bins=20)\n",
    "plt.title(\"Histogram incl. middle classes\")\n",
    "plt.legend(cat_lbl + [\"low\", \"high\"], loc=\"upper center\")\n",
    "plt.savefig(os.path.join(p_dir, \"histogram_w_medium.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08e5a1",
   "metadata": {},
   "source": [
    "# Grad-CAM class activation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    img = load_img(img_path, target_size=size)\n",
    "    array = img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def create_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = array_to_img(superimposed_img)\n",
    "\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_image(img_dir, id_video, last_cl, alpha=0.4, pred_class:str=\"low\"):\n",
    "    img_path = os.path.join(img_dir, \"{}.jpg\".format(row[\"id_video\"]))\n",
    "    img_array = get_img_array(img_path, size=(120, 90))\n",
    "    model.layers[-1].activation = None\n",
    "    preds = model.predict(img_array)\n",
    "    pred_idx = cat_lbl.index(pred_class)\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_cl, pred_idx)\n",
    "    img = create_gradcam(img_path, heatmap, os.path.join(p_dir, \"cam_{}.jpg\".format(row[\"id_video\"])), alpha)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d9f86-4b5b-449b-9f3f-ccf56cf0ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(\"conv\\d+_block\\d+_concat\")\n",
    "p2 = re.compile(\"conv(\\d+)_block(\\d+)_concat\")\n",
    "conv_layers = dict()\n",
    "for layer in model.layers:\n",
    "    if p.match(layer.name):\n",
    "        m = p2.search(layer.name)\n",
    "        if m:\n",
    "            conv_layers[m.group(1)] = m.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"conv{}_block{}_concat\".format(k, v) for k, v in conv_layers.items()]\n",
    "for layer in model.layers:\n",
    "    if layer.name in target_names:        \n",
    "        alpha = 0.8\n",
    "\n",
    "        fig, axs = plt.subplots(len(cat_lbl), 5)\n",
    "        i = 0\n",
    "        for idx, row in s.iterrows():\n",
    "            img_path = os.path.join(img_dir, \"{}.jpg\".format(row[\"id_video\"]))\n",
    "            img = cam_image(img_dir, row[\"id_video\"], layer.name, alpha, row[\"qtl\"])\n",
    "            axs[i // 5, i % 5].imshow(img)\n",
    "            axs[i // 5, i % 5].xaxis.set_ticklabels([])\n",
    "            axs[i // 5, i % 5].xaxis.set_ticks([])\n",
    "            axs[i // 5, i % 5].set_xlabel(row[\"qtl\"])\n",
    "            axs[i // 5, i % 5].yaxis.set_ticklabels([])\n",
    "            axs[i // 5, i % 5].yaxis.set_ticks([])\n",
    "            i += 1\n",
    "        plt.suptitle(\"Layer: {}\".format(layer.name))\n",
    "        plt.tight_layout()        \n",
    "        plt.show()\n",
    "        fig.savefig(os.path.join(p_dir, \"cam_sample_{}.jpg\".format(layer.name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0bd1e-f54f-47be-aa54-2e9ff1db9163",
   "metadata": {},
   "source": [
    "# 20 sample images for survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07ea79-ad54-4cb6-b023-30d5a2a7557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = combo.loc[combo[\"id_video\"].isin(x_val[\"id_video\"]), [\"id_video\", \"qtl\"]].groupby(\"qtl\", as_index=False).apply(lambda x: x.sample(10, random_state=57))\n",
    "survey = survey.sample(frac=1)\n",
    "\n",
    "print(survey.shape)\n",
    "\n",
    "s_dir = os.path.join(\"../img models\", m_name, \"survey images\")\n",
    "create_dir(s_dir)\n",
    "clear_dir(s_dir)\n",
    "\n",
    "for idx, row in survey.iterrows():\n",
    "    copyfile(os.path.join(img_dir, \"{}.jpg\".format(row[\"id_video\"])), os.path.join(s_dir, \"{}_{}.jpg\".format(row[\"id_video\"], row[\"qtl\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d83357-5231-4a7d-8fc2-bf698281250a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save test set pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad72b1f-fc5b-4b45-8b86-5d4ef73758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.Series(y_pred, name=\"y_pred_test\")\n",
    "y_pred_test.to_pickle(os.path.join(p_dir, \"y_pred_test.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
