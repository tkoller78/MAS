{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3469ff78-2149-41a4-93ac-a90a5d6fafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shutil import rmtree, copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from keras.layers import Input, Bidirectional, GlobalMaxPool1D, Dense, Dropout, LSTM, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c9237-e43a-4a35-b929-877958c81f2a",
   "metadata": {},
   "source": [
    "# Project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85cd8d0d-2841-4449-ad43-f1bc7a572822",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = \"distilbert_2_classes_v2\"\n",
    "p_dir = os.path.join(\"../nlp models\", m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ad907c-35b5-4f75-92ed-26f7825150b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path: str):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649c998a-1e01-4e75-bf29-baad4a10ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir(dir_path: str):\n",
    "    for item in os.listdir(dir_path):\n",
    "        fp = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(fp):\n",
    "            os.remove(fp)\n",
    "        if os.path.isdir(fp):\n",
    "            rmtree(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f916ce-e5a8-4c77-baeb-64511b0937e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(p_dir)\n",
    "clear_dir(p_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50c8ba-6b4d-438a-96ed-e7667b87d297",
   "metadata": {},
   "source": [
    "# Read and transform scraped dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c51e71a-9184-4302-b55a-60f283442bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../scraped data\"\n",
    "\n",
    "channels = pd.read_pickle(os.path.join(fp, \"channels.pkl\"))\n",
    "videos = pd.read_pickle(os.path.join(fp, \"videos.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7ca9f1-6de6-4e8e-9be5-392ced4a0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_channels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Date string into proper date\n",
    "    df.published = pd.to_datetime(df.published)\n",
    "    \n",
    "    # Convert field type into int64\n",
    "    fields = [\"video_count\", \"view_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"int64\")\n",
    "    \n",
    "    # Convert field type into float64\n",
    "    fields = [\"subscriber_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"float64\")\n",
    "    \n",
    "    # Add of channel in months\n",
    "    df[\"age_mth\"] = (pd.to_datetime(\"today\", utc=True).year - df.published.dt.year) * 12 \\\n",
    "        + (pd.to_datetime(\"today\", utc=True).month - df.published.dt.month)\n",
    "        \n",
    "    # Drop unnecessary fields\n",
    "    df.drop(columns=[\"custom_url\", \"country\"] + [c for c in df.columns if c.startswith(\"thumbnail\")], inplace=True)\n",
    "    \n",
    "    # Remove channels without subscriber_count\n",
    "    df = df.loc[df.subscriber_count.notnull(), :]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1195b7-0e97-4a76-aeee-ca10dec06a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_videos(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    # Date string into proper date\n",
    "    df.published = pd.to_datetime(df.published)\n",
    "    \n",
    "    # Convert field type to bool\n",
    "    fields = [\"broadcast\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"bool\")\n",
    "    \n",
    "    # Convert field type into int64\n",
    "    fields = [\"category_id\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"int64\")\n",
    "    \n",
    "    # Convert field type into float64\n",
    "    fields = [\"comment_count\", \"dislike_count\", \"like_count\", \"view_count\"]\n",
    "    df.loc[:, fields] = df.loc[:, fields].astype(\"float64\")\n",
    "    \n",
    "    df[\"published_mth\"] = (pd.to_datetime(\"today\", utc=True).year - df.published.dt.year) * 12 \\\n",
    "        + (pd.to_datetime(\"today\", utc=True).month - df.published.dt.month)\n",
    "    df[\"title_len\"] = df.title.str.len()\n",
    "    \n",
    "    df.drop(columns=[\"favorite_count\", \"broadcast\", \"audio_language\", \"comment_count\", \"category_id\"] \\\n",
    "            + [c for c in df.columns if c.startswith(\"thumbnail\")], inplace=True)\n",
    "    \n",
    "    df = df.loc[df.like_count.notnull() & df.dislike_count.notnull() & df.view_count.notnull(), :]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4f699f-8c3d-442c-911e-d0533284cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_trans = transform_channels(channels)\n",
    "videos_trans = transform_videos(videos)\n",
    "combo = videos_trans.merge(channels_trans[[\"id\", \"view_count\",\"published\", \"age_mth\", \"subscriber_count\",\n",
    "                                             \"video_count\"]], \n",
    "                           how=\"inner\", left_on=\"channel_id\", right_on=\"id\", suffixes=[\"_video\", \"_channel\"])\n",
    "combo[\"ln_vc_norm\"] = np.log(combo.video_count / combo.subscriber_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ff4b0-c209-4dfa-9018-d0579a0a2640",
   "metadata": {},
   "source": [
    "# Define categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c529e2b9-834d-4602-8d3e-e2ac89ed0cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_lbl = [\"very low\", \"low\", \"high\", \"very high\"]\n",
    "combo.loc[:, \"qtl\"] = pd.qcut(combo.ln_vc_norm, len(cat_lbl), labels=cat_lbl, precision=6)\n",
    "combo.sort_values(by=[\"qtl\"]).qtl.hist()\n",
    "plt.title(\"Counts of classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383e2e6-6ecc-49d1-81aa-25ddf61b62b4",
   "metadata": {},
   "source": [
    "# Split dataset (use only top and bottom quartile data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b00fc34-0dd4-48d4-8bc3-2dfe636c59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5526 1842 1843\n"
     ]
    }
   ],
   "source": [
    "cat_lbl = [\"very low\", \"very high\"]\n",
    "combo = combo.loc[combo.qtl.isin(cat_lbl)]\n",
    "combo.qtl = combo.qtl.cat.remove_unused_categories()\n",
    "\n",
    "y = combo.qtl\n",
    "x = combo.loc[:, [c for c in combo.columns if c != \"qtl\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=4711)\n",
    "\n",
    "x_train.to_pickle(os.path.join(p_dir, \"x_train.pkl\"))\n",
    "y_train.to_pickle(os.path.join(p_dir, \"y_train.pkl\"))\n",
    "x_val.to_pickle(os.path.join(p_dir,\"x_val.pkl\"))\n",
    "y_val.to_pickle(os.path.join(p_dir, \"y_val.pkl\"))\n",
    "x_test.to_pickle(os.path.join(p_dir,\"x_test.pkl\"))\n",
    "y_test.to_pickle(os.path.join(p_dir, \"y_test.pkl\"))\n",
    "\n",
    "print(x_train.shape[0], x_val.shape[0], x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fe01f-817f-4c30-bb51-5cdfe40bebc0",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902eff8b-3ad5-45e0-b9a3-1625a8e994d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df: pd.DataFrame, remove_stopwords: bool=False) -> pd.DataFrame:\n",
    "    field = \"title\"\n",
    "    stw = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def cleanse_row(row, field, stw, stopwords=False):\n",
    "        # Remove HTML from text\n",
    "        soup = BeautifulSoup(row[field])\n",
    "        row[field] = soup.get_text()\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if stopwords:\n",
    "            row[field] = \" \".join([w for w in row[field].split() if w not in stw])\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    df = df.apply(lambda row: cleanse_row(row, field, stw, remove_stopwords), axis=1)\n",
    "    return df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3c65b7-b46e-45f6-a5d4-c224017f46ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwork corpus\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f0605a-39e5-4b24-a655-4d2e663f91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = False\n",
    "\n",
    "def preprocess_data(x: pd.DataFrame, remove_stopwords: bool=False) -> list():\n",
    "    x_pp = preprocessing(x, remove_stopwords)\n",
    "    x_pp = x_pp.tolist()\n",
    "    return x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3095d20-48e6-4af6-918a-17a2d5d9a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pp = preprocess_data(x_train)\n",
    "x_test_pp = preprocess_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a668f102-1e7a-4700-814f-4e78c0bd9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = \"distilbert-base-uncased\"\n",
    "tok = DistilBertTokenizer.from_pretrained(pt_model, do_lower=True, add_special_tokens=True, max_length=100, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af0d7567-2876-480a-8b9f-5709c2c1b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=100, padding=\"max_length\", return_attention_mask=True, \n",
    "                                       return_token_type_ids=True)\n",
    "        input_ids.append(inputs[\"input_ids\"])\n",
    "        input_masks.append(inputs[\"attention_mask\"])\n",
    "        input_segments.append(inputs[\"token_type_ids\"])\n",
    "        \n",
    "    return np.asarray(input_ids, dtype=\"int32\"), np.asarray(input_masks, dtype=\"int32\"), np.asarray(input_segments, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35e83f65-c8c2-46b8-b7a6-99226fd9e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "config.output_hidden_states=False\n",
    "transformer_model = TFDistilBertModel.from_pretrained(pt_model, config=config)\n",
    "\n",
    "in_ids = Input(shape=(100,), name=\"input_token\", dtype=\"int32\")\n",
    "in_masks = Input(shape=(100,), name=\"masked_token\", dtype=\"int32\")\n",
    "\n",
    "emb = transformer_model(in_ids, attention_mask=in_masks)[0]\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(emb)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=[in_ids, in_masks], outputs=x)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb4ff5ed-434e-4ed8-86d4-bc162c6707b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_11 (TFDist TFBaseModelOutput(la 66362880    input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 100, 100)     327600      tf_distil_bert_model_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 100)          0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           global_max_pooling1d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 50)           5050        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_237 (Dropout)           (None, 50)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            102         dropout_237[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 66,695,632\n",
      "Trainable params: 332,752\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9a55c-bd5f-4426-92dd-9de618ad7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 88s 913ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.1082 - val_accuracy: 0.9658\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96582, saving model to ../nlp models/distilbert_2_classes_v2/distilbert_2_classes_v2\n",
      "Epoch 2/20\n",
      "38/87 [============>.................] - ETA: 39s - loss: 0.0330 - accuracy: 0.9897"
     ]
    }
   ],
   "source": [
    "x_train_tok = tokenize(x_train_pp, tok)\n",
    "x_test_tok = tokenize(x_test_pp, tok)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train_b = lb.fit_transform(y_train)\n",
    "y_test_b = lb.transform(y_test)\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=Adam(learning_rate=0.0005), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "metric = \"val_accuracy\"\n",
    "\n",
    "es = EarlyStopping(monitor=metric, \n",
    "                   mode=\"max\", \n",
    "                   patience=5, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(p_dir, \"{}\".format(m_name)), \n",
    "                             monitor=metric, \n",
    "                             verbose=2, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "hist = model.fit(x_train_tok[:2], y_train_b, \n",
    "                 validation_data=(x_test_tok[:2], y_test_b), \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=n_epochs, \n",
    "                 callbacks=[checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056c121-ecf4-4536-b16c-2f0f4b32a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(hist.history[\"accuracy\"])\n",
    "axs[0].plot(hist.history[\"val_accuracy\"])\n",
    "axs[0].set_title(\"model accuracy\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].set_xlabel(\"epoch\")\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "axs[1].plot(hist.history[\"loss\"])\n",
    "axs[1].plot(hist.history[\"val_loss\"])\n",
    "axs[1].set_title(\"model loss\")\n",
    "axs[1].set_ylabel(\"loss\")\n",
    "axs[1].set_xlabel(\"epoch\")\n",
    "# axs[1].set_ylim(0, 1)\n",
    "axs[1].legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(p_dir, \"accuracy_loss.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
